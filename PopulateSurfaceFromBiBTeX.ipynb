{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Populate SURFACE from BibTeX\n",
    "\n",
    "**Duncan A. Brown<sup>1</sup>**\n",
    "\n",
    "**<sup>1</sup>Department of Physics, Syracuse University, Syracuse, NY 13244, USA**\n",
    "\n",
    "This script will populate SURFACE with publications that are downloaded in a BibTeX file from ORCID, INSPIRES, or ADS.\n",
    "\n",
    "## License\n",
    "\n",
    "This work is licensed under a [Creative Commons Attribution-ShareAlike 3.0 United States License](http://creativecommons.org/licenses/by-sa/3.0/us/).\n",
    "\n",
    "## Instructions\n",
    "\n",
    "1. Create a Python virtual environment with\n",
    "```sh\n",
    "virtualenv ~/surface\n",
    "```\n",
    "and then activate it with\n",
    "```sh\n",
    "source ~/surface/bin/activate\n",
    "```\n",
    "2. Install the required Python packages\n",
    "```sh\n",
    "pip install --upgrade pip\n",
    "pip install --upgrade setuptools\n",
    "pip install jupyter\n",
    "pip install selenium\n",
    "pip install bibtexparser\n",
    "pip install bs4\n",
    "```\n",
    "3. Install the [headless Chrome](https://developers.google.com/web/updates/2017/04/headless-chrome) driver using [Homebrew](https://brew.sh/)\n",
    "```sh\n",
    "brew cask install chromedriver\n",
    "```\n",
    "3. Follow the [export works instructions](https://support.orcid.org/hc/en-us/articles/360006971453-Exporting-works-into-a-BibTeX-file) to download your works from ORCID as a bibtex file. Save it in the same directory as this notebook.\n",
    "4. Execute this notebook. The first two cells ask for your NetID and password, so enter them when prompted.\n",
    "\n",
    "## Enter NetID and Password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter NetID\n",
      "dabrown\n"
     ]
    }
   ],
   "source": [
    "print \"Enter NetID\"\n",
    "netid = raw_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter NetID Password\n",
      "········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "print \"Enter NetID Password\"\n",
    "password = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your ORCID with the URL (i.e. in the form https://orcid.org/0000-0002-9180-5765)\n",
      "https://orcid.org/0000-0002-9180-5765\n"
     ]
    }
   ],
   "source": [
    "print \"Enter your ORCID with the URL (i.e. in the form https://orcid.org/0000-0002-9180-5765)\"\n",
    "orcid = raw_input()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules and launch the Chrome headless driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "import urllib\n",
    "import urllib2\n",
    "import bibtexparser\n",
    "from bibtexparser.bwriter import BibTexWriter\n",
    "from bibtexparser.bibdatabase import BibDatabase\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from bs4 import BeautifulSoup as Soup\n",
    "from collections import defaultdict\n",
    "import AddressBook as ab\n",
    "from __future__ import unicode_literals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_obj(obj, name ):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name ):\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('/usr/local/bin/chromedriver')\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    author_emails = load_obj('author_emails')\n",
    "except:\n",
    "    author_emails = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in a BibTeX file created by exporting works from ORCID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del bib_database\n",
    "except:\n",
    "    pass\n",
    "with open('works.bib') as bibtex_file:\n",
    "    bib_database = bibtexparser.load(bibtex_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open a connection to SURFACE\n",
    "\n",
    "This will bounce us through the SAML2 authentication to Syracuse University's IdP and back to SURFACE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://shibidp.syr.edu/idp/profile/cas/login?service=https%3A%2F%2Fsurface.syr.edu%2Fcgi%2Flogin.cgi%3Fauth_server%3D21%26return_to%3Dhttps%253A%252F%252Fsurface.syr.edu%252Fcgi%252Fir_submit.cgi%253Fcontext%253Dphy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element_by_id('username').send_keys(netid)\n",
    "driver.find_element_by_id('password').send_keys(password)\n",
    "driver.find_element_by_name('_eventId_proceed').click()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to query the OS X address book to find emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_list(cdw):\n",
    "    \"\"\"Make a list from CoreDataWrapper\"\"\"\n",
    "    if not cdw:\n",
    "        return []\n",
    "    values = []\n",
    "    for i in range(cdw.count()):\n",
    "        values.append(unicode(cdw.valueAtIndex_(i)))\n",
    "    return values\n",
    "\n",
    "\n",
    "# map dict keys to AB properties and conversion funcs\n",
    "_text_property_map = {\n",
    "    # output key :  (property, conversion func)\n",
    "    'first_name': (ab.kABFirstNameProperty, None),\n",
    "    'last_name': (ab.kABLastNameProperty, None),\n",
    "    'company': (ab.kABOrganizationProperty, None),\n",
    "    'emails': (ab.kABEmailProperty, _make_list),\n",
    "}\n",
    "\n",
    "\n",
    "def ab_person_to_dict(person):\n",
    "    \"\"\"Convert ABPerson to Python dict\"\"\"\n",
    "    d = {}\n",
    "    d['emails'] = []\n",
    "    for key in _text_property_map:\n",
    "        prop, func = _text_property_map[key]\n",
    "        value = person.valueForProperty_(prop)\n",
    "        if func:\n",
    "            value = func(value)\n",
    "        if not value:\n",
    "            value = ''\n",
    "        d[key] = value\n",
    "    return d\n",
    "\n",
    "\n",
    "def search(query):\n",
    "    \"\"\"Search Mac Address Book and return pythonified results\"\"\"\n",
    "\n",
    "    address_book = ab.ABAddressBook.sharedAddressBook()\n",
    "    # build search criteria\n",
    "    criteria = []\n",
    "    for key in _text_property_map:\n",
    "        prop, func = _text_property_map[key]\n",
    "        criteria.append(\n",
    "            ab.ABPerson.searchElementForProperty_label_key_value_comparison_(\n",
    "            prop,\n",
    "            None, None,\n",
    "            query,\n",
    "            ab.kABContainsSubStringCaseInsensitive)\n",
    "        )\n",
    "\n",
    "    search = ab.ABSearchElement.searchElementForConjunction_children_(\n",
    "            ab.kABSearchOr, criteria)\n",
    "\n",
    "    # search Address Book\n",
    "    people = address_book.recordsMatchingSearchElement_(search)\n",
    "\n",
    "    results = defaultdict(set)\n",
    "    for person in [ab_person_to_dict(person) for person in people]:\n",
    "        key = '{} {}'.format(person.get('first_name', ''),\n",
    "                             person.get('last_name', '')).strip()\n",
    "        for addr in person['emails']:\n",
    "            results[key].add(addr)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to get the URL of a PDF from ArXiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_arxiv_pdf_from_doi(doi):\n",
    "        \n",
    "    response = urllib2.urlopen('https://arxiv.org/search/advanced?advanced=1'\n",
    "                               '&terms-0-operator=AND&terms-0-term={}'\n",
    "                               '&terms-0-field=doi&classification-physics_archives=all'\n",
    "                               '&date-filter_by=all_dates&date-year=&date-from_date='\n",
    "                               '&date-to_date=&date-date_type=submitted_date'\n",
    "                               '&abstracts=show&size=50'\n",
    "                               '&order=-announced_date_first'.format(urllib.quote_plus(doi)))\n",
    "    \n",
    "    html = response.read()\n",
    "    page = Soup(html,'html.parser')\n",
    "    \n",
    "    pdf_link = None\n",
    "    for a in page.find_all('a'):\n",
    "        try:\n",
    "            href = str(a['href'])\n",
    "            if 'https://arxiv.org/pdf/' in href:\n",
    "                pdf_link = href\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    return pdf_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_authors(driver, bibkey):\n",
    "    \n",
    "    driver.find_element_by_css_selector('a.remove').click()\n",
    "    \n",
    "    author_index = 0\n",
    "    \n",
    "    for a in authors:\n",
    "        author_index +=1\n",
    "        a = re.sub(\"{|}\", \"\", a).strip()\n",
    "                \n",
    "        if ',' in a:\n",
    "            l, others = a.split(',')\n",
    "            others = others.strip()\n",
    "            names = others.split(' ')\n",
    "            if len(names) == 2:\n",
    "                f, m = names\n",
    "            elif len(names) == 1:\n",
    "                f = names[0]\n",
    "                m = ''\n",
    "            else:\n",
    "                f = names[0]\n",
    "                m = None\n",
    "        else:\n",
    "            names = a.split(' ')\n",
    "            if len(names) == 3:\n",
    "                f, m, l = names\n",
    "            elif len(names) == 2:\n",
    "                f, l = names\n",
    "                m = ''\n",
    "            else:\n",
    "                f = names[0]\n",
    "                m = None\n",
    "                l = names[-1]\n",
    "\n",
    "        \n",
    "        f.strip()\n",
    "        m.strip()\n",
    "        l.strip()\n",
    "\n",
    "        if a in author_emails:\n",
    "            e = author_emails[a][0]\n",
    "            i = author_emails[a][1]\n",
    "        else:\n",
    "            e = None\n",
    "            people = search(l)\n",
    "            if len(people):\n",
    "                try:\n",
    "                    e = [value for key, value in people.items() if f.lower() in key.lower()][0].pop()\n",
    "                except:\n",
    "                    e = None\n",
    "                \n",
    "            if e is None:\n",
    "                print \"I need to know the email address for {}\".format(a)\n",
    "                e = raw_input()\n",
    "            \n",
    "            try:\n",
    "                if e.split('@')[1] == 'syr.edu':\n",
    "                    i = \"Syracuse University\"\n",
    "                else:\n",
    "                    i = None\n",
    "            except:\n",
    "                i = None\n",
    "                \n",
    "            if i is None:\n",
    "                print \"I need to know the institution for {}\".format(a)\n",
    "                i = raw_input()\n",
    "            \n",
    "            author_emails[a] = (e, i)\n",
    "            \n",
    "        if author_index == 1:\n",
    "            driver.find_element_by_xpath('//*[@title=\"Show/hide details\"]').click()\n",
    "        else:\n",
    "            ap = driver.find_element_by_id('ap_picker')\n",
    "            ap.send_keys(a)\n",
    "            \n",
    "            time.sleep(5)\n",
    "            c = ap.get_attribute('aria-owns')\n",
    "            driver.find_element_by_id(c).click()\n",
    "            \n",
    "        time.sleep(2)        \n",
    "        driver.find_element_by_name('email_{}'.format(author_index)).send_keys(e)\n",
    "        driver.find_element_by_name('fname_{}'.format(author_index)).send_keys(f)\n",
    "        driver.find_element_by_name('mname_{}'.format(author_index)).send_keys(m)\n",
    "        driver.find_element_by_name('lname_{}'.format(author_index)).send_keys(l)\n",
    "        \n",
    "        ip = driver.find_element_by_name('institution_{}'.format(author_index))\n",
    "        ip.send_keys(i)\n",
    "        \n",
    "        try:\n",
    "            time.sleep(2)\n",
    "            c = ip.get_attribute('aria-owns')\n",
    "            driver.find_element_by_id(c).click()\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    driver.find_element_by_id('min_{}'.format(author_index)).click()        \n",
    "    \n",
    "    print \"OK to continue?\"\n",
    "    x = raw_input()\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_entry(driver, bibkey):\n",
    "    \n",
    "    if 'doi'in bibkey:\n",
    "        doi = urllib2.unquote(bibkey['doi'])\n",
    "    else:\n",
    "        print \"No DOI found for entry, skipping {}\".format(bibkey['title'])\n",
    "        return False, bibkey\n",
    "    \n",
    "    pdf_link = get_arxiv_pdf_from_doi(doi)\n",
    "    \n",
    "    print \"Uploading {}\".format(doi)\n",
    "    \n",
    "    driver.get('https://shibidp.syr.edu/idp/profile/cas/login?service=https%3A%2F%2Fsurface.syr.edu%2Fcgi%2Flogin.cgi%3Fauth_server%3D21%26return_to%3Dhttps%253A%252F%252Fsurface.syr.edu%252Fcgi%252Fir_submit.cgi%253Fcontext%253Dphy')\n",
    "    \n",
    "    try:\n",
    "        driver.find_element_by_css_selector('a.cc-btn.cc-dismiss').click()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    time.sleep(5)\n",
    "    driver.find_element_by_name('accept_agreement').click()\n",
    "    driver.find_element_by_name('agreement_button').click()\n",
    "    time.sleep(5)\n",
    "\n",
    "    driver.find_element_by_id('title').send_keys(re.sub(\"{|}\", \"\", bibkey['title']))\n",
    "    \n",
    "    if not populate_authors(driver, bibkey):\n",
    "        print \"Skipping {} due to incomplete author information\".format(bibkey['title'])\n",
    "        return False, bibkey\n",
    "    \n",
    "    ifr = driver.find_element_by_id('orcid_ifr')\n",
    "    driver.switch_to.frame(ifr)\n",
    "    driver.find_element_by_id('tinymce').send_keys(orcid)\n",
    "    driver.switch_to.default_content()\n",
    "    \n",
    "    driver.find_element_by_id('publication_date_year').send_keys(bibkey['year'])\n",
    "    \n",
    "    time.sleep(2)\n",
    "    driver.find_element_by_id('keywords').send_keys('gravitational wave astronomy astrophysics')\n",
    "    \n",
    "    select_box = driver.find_element_by_id('disciplines')\n",
    "    options = [x for x in select_box.find_elements_by_tag_name(\"option\")]\n",
    "    for o in options:\n",
    "        o.click()\n",
    "    driver.find_element_by_xpath(u'//*[@value=\"« Remove\"]').click()\n",
    "    \n",
    "    driver.find_element_by_id('ygtvlabelel9').click()\n",
    "    time.sleep(2)\n",
    "    driver.find_element_by_id('ygtvlabelel12').click()\n",
    "    time.sleep(2)\n",
    "    driver.find_element_by_id('ygtvlabelel22').click()\n",
    "    time.sleep(2)\n",
    "    driver.find_element_by_xpath(u'//*[@value=\"Select »\"]').click()\n",
    "    \n",
    "    if pdf_link:\n",
    "        ifr = driver.find_element_by_id('comments_ifr')\n",
    "        driver.switch_to.frame(ifr)\n",
    "        driver.find_element_by_id('tinymce').send_keys(pdf_link)\n",
    "        driver.switch_to.default_content()\n",
    "\n",
    "    driver.find_element_by_id('link_full_text').click()\n",
    "    driver.find_element_by_xpath(u'//*[@name=\"source_fulltext_url\"]').send_keys(\n",
    "        'https://doi.org/{}'.format(doi))\n",
    "    \n",
    "    ifr = driver.find_element_by_id('doi_ifr')\n",
    "    driver.switch_to.frame(ifr)\n",
    "    driver.find_element_by_id('tinymce').send_keys(doi)\n",
    "    driver.switch_to.default_content()\n",
    "\n",
    "    driver.find_element_by_id('source').send_keys('submission')\n",
    "    \n",
    "    x = raw_input('OK to submit? Hit return to continue or type anything else to cancel')\n",
    "    if x.strip() == '':\n",
    "        driver.find_element_by_xpath(u'//*[@name=\"submit_paper\"]').click()\n",
    "        return True, bibkey\n",
    "    else:\n",
    "        return False, bibkey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping Aartsen:2014mfp due to author information\n",
      "Skipping Aasi:2012fw due to author information\n",
      "Skipping Aasi:2012rja due to author information\n",
      "Skipping Aasi:2012wd due to author information\n",
      "Skipping Aasi:2013jjl due to author information\n",
      "Skipping Aasi:2013jya due to author information\n",
      "Skipping Aasi:2013lva due to author information\n",
      "Skipping Aasi:2013sia due to author information\n",
      "Skipping Aasi:2013sna due to author information\n",
      "Skipping Aasi:2013vna due to author information\n",
      "Skipping Aasi:2014bqj due to author information\n",
      "Skipping Aasi:2014ent due to author information\n",
      "Skipping Aasi:2014erp due to author information\n",
      "Skipping Aasi:2014iia due to author information\n",
      "Skipping Aasi:2014iwa due to author information\n",
      "Skipping Aasi:2014jkh due to author information\n",
      "Skipping Aasi:2014jln due to author information\n",
      "Skipping Aasi:2014ksa due to author information\n",
      "Skipping Aasi:2014mqd due to author information\n",
      "Skipping Aasi:2014mtf due to author information\n",
      "Skipping Aasi:2014qak due to author information\n",
      "Skipping Aasi:2014tra due to author information\n",
      "Skipping Aasi:2014zwg due to author information\n",
      "Skipping Aasi:2015rar due to author information\n",
      "Skipping Aasi:2015ssf due to author information\n",
      "Skipping Abadie:2010cf due to author information\n",
      "Skipping Abadie:2010cg due to author information\n",
      "Skipping Abadie:2010hv due to author information\n",
      "Skipping Abadie:2010mt due to author information\n",
      "Skipping Abadie:2010px due to author information\n",
      "Skipping Abadie:2010sf due to author information\n",
      "Skipping Abadie:2010uf due to author information\n",
      "Skipping Abadie:2010wx due to author information\n",
      "Skipping Abadie:2010yb due to author information\n",
      "Skipping Abadie:2011fx due to author information\n",
      "Skipping Abadie:2011kd due to author information\n",
      "Skipping Abadie:2011md due to author information\n",
      "Skipping Abadie:2011rr due to author information\n",
      "Skipping Abadie:2011wj due to author information\n",
      "Skipping Abadie:2011xta due to author information\n",
      "Skipping Abadie:2012bz due to author information\n",
      "Skipping Abadie:2012rq due to author information\n",
      "Skipping Abbott:2003hr due to author information\n",
      "Skipping Abbott:2003pb due to author information\n",
      "Skipping Abbott:2003pj due to author information\n",
      "Skipping Abbott:2003vs due to author information\n",
      "Skipping Abbott:2003yq due to author information\n",
      "Skipping Abbott:2004ig due to author information\n",
      "Skipping Abbott:2004rt due to author information\n",
      "Skipping Abbott:2005at due to author information\n",
      "Skipping Abbott:2005ez due to author information\n",
      "Skipping Abbott:2005fb due to author information\n",
      "Skipping Abbott:2005kq due to author information\n",
      "Skipping Abbott:2005pe due to author information\n",
      "Skipping Abbott:2005pf due to author information\n",
      "Skipping Abbott:2005pu due to author information\n",
      "Skipping Abbott:2005qm due to author information\n",
      "Skipping Abbott:2005rt due to author information\n",
      "Skipping Abbott:2005yy due to author information\n",
      "Skipping Abbott:2006vg due to author information\n",
      "Skipping Abbott:2006zx due to author information\n",
      "Skipping Abbott:2007ai due to author information\n",
      "Skipping Abbott:2007ce due to author information\n",
      "Skipping Abbott:2007kv due to author information\n",
      "Skipping Abbott:2007rh due to author information\n",
      "Skipping Abbott:2007td due to author information\n",
      "Skipping Abbott:2007tw due to author information\n",
      "Skipping Abbott:2007wd due to author information\n",
      "Skipping Abbott:2007wu due to author information\n",
      "Skipping Abbott:2007xi due to author information\n",
      "Skipping Abbott:2007zzb due to author information\n",
      "Skipping Abbott:2008be due to author information\n",
      "Skipping Abbott:2008fx due to author information\n",
      "Skipping Abbott:2008gj due to author information\n",
      "Skipping Abbott:2008mr due to author information\n",
      "Skipping Abbott:2008rg due to author information\n",
      "Skipping Abbott:2008uq due to author information\n",
      "Skipping Abbott:2008zzb due to author information\n",
      "Skipping Abbott:2009kk due to author information\n",
      "Skipping Abbott:2009km due to author information\n",
      "Skipping Abbott:2009nc due to author information\n",
      "Skipping Abbott:2009qj due to author information\n",
      "Skipping Abbott:2009rr due to author information\n",
      "Skipping Abbott:2009tt due to author information\n",
      "Skipping Abbott:2009up due to author information\n",
      "Skipping Abbott:2009ws due to author information\n",
      "Skipping Abbott:2009zd due to author information\n",
      "Skipping Abbott:2009zi due to author information\n",
      "Skipping Abbott:2009zz due to author information\n",
      "Skipping Abbott:2011ys due to author information\n",
      "Skipping Abbott:2015vir due to author information\n",
      "Skipping Abbott:2016apu due to author information\n",
      "Skipping Abbott:2016blz due to author information\n",
      "Skipping Abbott:2016bqf due to author information\n",
      "Skipping Abbott:2016cjt due to author information\n",
      "Skipping Abbott:2016drs due to author information\n",
      "Skipping Abbott:2016ezn due to author information\n",
      "Skipping Abbott:2016gcq due to author information\n",
      "Skipping Abbott:2016iqz due to author information\n",
      "Skipping Abbott:2016izl due to author information\n",
      "Skipping Abbott:2016jsd due to author information\n",
      "Skipping Abbott:2016nhf due to author information\n",
      "Skipping Abbott:2016nmj due to author information\n",
      "Skipping Abbott:2016tdt due to author information\n",
      "Skipping Abbott:2016tvg due to author information\n",
      "Skipping Abbott:2016udd due to author information\n",
      "Skipping Abbott:2016wiq due to author information\n",
      "Skipping Abbott:2016ymx due to author information\n",
      "Skipping Abbott:2017eaw due to author information\n",
      "Skipping Abbott:2017gyy due to author information\n",
      "Skipping Abbott:2017hbu due to author information\n",
      "Skipping Abbott:2017iws due to author information\n",
      "Skipping Abbott:2017mnu due to author information\n",
      "Skipping Abbott:2017mwl due to author information\n",
      "Skipping Abbott:2017oio due to author information\n",
      "Skipping Abbott:2017pqa due to author information\n",
      "Skipping Abbott:2017vtc due to author information\n",
      "Skipping Abbott:2017xzu due to author information\n",
      "Skipping Abbott:2017ylp due to author information\n",
      "Skipping AdrianMartinez:2012tf due to author information\n",
      "Skipping Ajith:2012az due to author information\n",
      "Skipping Alexander:2017aly due to author information\n",
      "Skipping Allen:2003ww due to author information\n",
      "Skipping ANTARES:2017bia due to author information\n",
      "Skipping ANTARES:2017iky due to author information\n",
      "Skipping Aylott:2009tn due to author information\n",
      "Skipping Aylott:2009ya due to author information\n",
      "Skipping Babak:2007zd due to author information\n",
      "Skipping Babak:2012zx due to author information\n",
      "Skipping Baggio:2007pa due to author information\n",
      "Skipping Barkett:2015wia due to author information\n",
      "Skipping Belczynski:2017gds due to author information\n",
      "Skipping Biwer:2016oyg due to author information\n",
      "Skipping Blanchard:2017csd due to author information\n",
      "Skipping Briggs:2012ce due to author information\n",
      "Skipping Brown:2003pv due to author information\n",
      "Uploading 10.1088/0264-9381/21/5/060\n",
      "No DOI found for entry, skipping Searching for gravitational radiation from binary black hole MACHOs in the galactic halo\n",
      "Uploading 10.1088/0264-9381/22/18/S24\n",
      "No DOI found for entry, skipping Data formats for numerical relativity waves\n",
      "Uploading 10.1088/0264-9381/24/19/S22\n",
      "I need to know the email address for Crowder, Jeff\n",
      "crowder@caltech.edu\n",
      "I need to know the institution for Crowder, Jeff\n",
      "Caltech\n",
      "I need to know the institution for Cutler, Curt\n",
      "Caltech\n",
      "I need to know the institution for Vallisneri, Michele\n",
      "Caltech\n",
      "OK to continue?\n",
      "\n",
      "OK to submit?\n",
      "Uploading 10.1103/PhysRevD.81.024007\n",
      "OK to continue?\n",
      "\n",
      "OK to submit?\n",
      "Uploading 10.1103/PhysRevD.86.064020\n",
      "I need to know the email address for O'Shaughnessy, R.\n",
      "rossma@rit.edu\n",
      "I need to know the institution for O'Shaughnessy, R.\n",
      "Rochesters Institute of Technology\n",
      "OK to continue?\n",
      "\n",
      "OK to submit?\n",
      "Skipping Cahillane:2017vkb due to author information\n",
      "Skipping Canton:2014ena due to author information\n",
      "Skipping Chornock:2017sdf due to author information\n",
      "Skipping Colaboration:2011np due to author information\n",
      "Skipping Collaboration:2009rfa due to author information\n",
      "Skipping Cowperthwaite:2016shk due to author information\n",
      "Skipping Cowperthwaite:2017dyu due to author information\n",
      "Skipping Evans:2012hd due to author information\n",
      "Skipping Evans:2016mbw due to author information\n",
      "Skipping Fong:2017ekk due to author information\n",
      "Skipping GBM:2017lvd due to author information\n",
      "Skipping Harry:2003xu due to author information\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading 10.1103/PhysRevD.86.024024\n",
      "OK to continue?\n",
      "\n",
      "OK to submit?\n",
      "Skipping Kumar:2013gwa due to author information\n",
      "Skipping LIGO:2012aa due to author information\n",
      "Uploading 10.1103/PhysRevD.78.124020\n",
      "I need to know the institution for Lindblom, Lee\n",
      "Caltech\n",
      "I need to know the email address for Owen, Benjamin J.\n",
      "Penn State\n",
      "I need to know the institution for Owen, Benjamin J.\n",
      "Penn State\n",
      "OK to continue?\n",
      "\n",
      "OK to submit?\n",
      "Uploading 10.1086/588246\n",
      "I need to know the email address for Miller, M.Coleman\n",
      "miller@astro.umd.edu\n",
      "I need to know the institution for Miller, M.Coleman\n",
      "University of Maryland\n",
      "OK to continue?\n",
      "\n",
      "OK to submit?\n",
      "Skipping Mandel:2013ara due to author information\n",
      "Skipping Margutti:2017cjl due to author information\n",
      "Skipping Martynov:2016fzi due to author information\n",
      "Skipping Monitor:2017mdv due to author information\n",
      "Skipping Nicholl:2017ahq due to author information\n",
      "Skipping others:2016ifn due to author information\n",
      "Uploading 10.1088/0264-9381/24/12/S06\n",
      "OK to continue?\n",
      "\n",
      "OK to submit?\n",
      "Skipping Singer:2013xha due to author information\n",
      "Skipping Slutsky:2010ff due to author information\n",
      "Skipping Soares-Santos:2016qeb due to author information\n",
      "Skipping Soares-Santos:2017lru due to author information\n",
      "Skipping TheLIGOScientific:2013cya due to author information\n",
      "Skipping TheLIGOScientific:2013nha due to author information\n",
      "Skipping TheLIGOScientific:2014jea due to author information\n",
      "Skipping TheLIGOScientific:2016agk due to author information\n",
      "Skipping TheLIGOScientific:2016dpb due to author information\n",
      "Skipping TheLIGOScientific:2016htt due to author information\n",
      "Skipping TheLIGOScientific:2016pea due to author information\n",
      "Skipping TheLIGOScientific:2016qqj due to author information\n",
      "Skipping TheLIGOScientific:2016src due to author information\n",
      "Skipping TheLIGOScientific:2016uns due to author information\n",
      "Skipping TheLIGOScientific:2016uux due to author information\n",
      "Skipping TheLIGOScientific:2016wfe due to author information\n",
      "Skipping TheLIGOScientific:2016xzw due to author information\n",
      "Skipping TheLIGOScientific:2016zmo due to author information\n",
      "Skipping TheLIGOScientific:2017lwt due to author information\n",
      "Skipping Usman:2015kfa due to author information\n",
      "Uploading 10.1103/PhysRevD.80.024009\n",
      "I need to know the institution for Van Den Broeck, Chris\n",
      "\n",
      "Skipping Virgo:2011aa due to author information\n",
      "Skipping Virgo:2012aa due to author information\n",
      "Skipping Weinstein:2003kkr due to author information\n"
     ]
    }
   ],
   "source": [
    "rejected_publications = []\n",
    "accepted_publications = []\n",
    "\n",
    "for b in bib_database.entries:\n",
    "    authors = b['author'].split(' and ')\n",
    "    \n",
    "    if authors[-1].strip().lower() == 'others':\n",
    "        print \"Skipping {} due to author information\".format(b['ID'])\n",
    "        rejected_publications.append(b)\n",
    "        \n",
    "    else:\n",
    "        try:\n",
    "            e, r = populate_entry(driver, b)\n",
    "            if e:\n",
    "                accepted_publications.append(r)\n",
    "            else:\n",
    "                rejected_publications.append(r)\n",
    "        except:\n",
    "            rejected_publications.append(b) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = BibTexWriter()\n",
    "\n",
    "rejected_bib = bibtexparser.bibdatabase.BibDatabase()\n",
    "rejected_bib.entries = rejected_publications\n",
    "\n",
    "accepted_bib = bibtexparser.bibdatabase.BibDatabase()\n",
    "accepted_bib.entries = accepted_publications\n",
    "\n",
    "with open('rejected_publications.bib', 'w') as bibfile:\n",
    "    bibfile.write(writer.write(rejected_bib).encode('utf-8'))\n",
    "    \n",
    "with open('accepted_publications.bib', 'w') as bibfile:\n",
    "    bibfile.write(writer.write(accepted_bib).encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_obj(author_emails,'author_emails')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
